{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pytho\\Documents\\GitHub\\GS-ADS-DOS-CRIA\\AI & CHATBOT\\MRI\\Model\\Modelo.ipynb Célula 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pytho/Documents/GitHub/GS-ADS-DOS-CRIA/AI%20%26%20CHATBOT/MRI/Model/Modelo.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m vgg16\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pytho/Documents/GitHub/GS-ADS-DOS-CRIA/AI%20%26%20CHATBOT/MRI/Model/Modelo.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pytho/Documents/GitHub/GS-ADS-DOS-CRIA/AI%20%26%20CHATBOT/MRI/Model/Modelo.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pytho/Documents/GitHub/GS-ADS-DOS-CRIA/AI%20%26%20CHATBOT/MRI/Model/Modelo.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━❮◆❯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━❮Bibliotecas❯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━❮◆❯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from sklearn.metrics import classification_report\n",
    "from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━❮◆❯━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localização dos arquivos\n",
    "## Alterar para usar colab (serão necessarios pelo menos 24gb RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = r'/content/drive/My Drive/MRI/Data/Testing'\n",
    "TRAIN_DIR = r'/content/drive/My Drive/MRI/Data/Training'\n",
    "IMG_SIZE = 224\n",
    "\n",
    "CATEGORIES = [\"glioma_tumor\",\"meningioma_tumor\",\"no_tumor\",\"pituitary_tumor\"]\n",
    "\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando Dataset Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 826/826 [00:06<00:00, 119.51it/s]\n",
      "100%|██████████| 822/822 [00:07<00:00, 106.20it/s]\n",
      "100%|██████████| 395/395 [00:03<00:00, 131.33it/s]\n",
      "100%|██████████| 827/827 [00:06<00:00, 123.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(TRAIN_DIR,category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "          img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_COLOR)\n",
    "          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "          training_data.append([new_array, class_num])\n",
    "\n",
    "    random.shuffle(training_data)\n",
    "\n",
    "create_training_data()\n",
    "#np.save('train_data.npy', training_data)\n",
    "print(len(training_data))\n",
    "\n",
    "print(\"train\")\n",
    "print()\n",
    "X_train = np.array([i[0] for i in training_data]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "Y_train = [i[1] for i in training_data]\n",
    "\n",
    "pickle_out = open(\"X_train.pickle\",\"wb\")\n",
    "pickle.dump(X_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y_train.pickle\",\"wb\")\n",
    "pickle.dump(Y_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando Dataset de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 96.41it/s]\n",
      "100%|██████████| 115/115 [00:00<00:00, 142.13it/s]\n",
      "100%|██████████| 105/105 [00:00<00:00, 155.28it/s]\n",
      "100%|██████████| 74/74 [00:00<00:00, 79.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n",
      "testing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_data = []\n",
    "\n",
    "def create_testing_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(TEST_DIR,category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "          img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_COLOR)\n",
    "          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "          testing_data.append([new_array, class_num])\n",
    "\n",
    "    random.shuffle(testing_data)\n",
    "\n",
    "create_testing_data()\n",
    "#np.save('testing_data.npy', testing_data)\n",
    "print(len(testing_data))\n",
    "\n",
    "print(\"testing\")\n",
    "print()\n",
    "X_test= np.array([i[0] for i in testing_data]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "Y_test = [i[1] for i in testing_data]\n",
    "\n",
    "pickle_out = open(\"X_test.pickle\",\"wb\")\n",
    "pickle.dump(X_test, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y_test.pickle\",\"wb\")\n",
    "pickle.dump(Y_test, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições de TensorBoard e EarlyStopping para evitar overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tensorboard = TensorBoard(log_dir='./VGG16logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando CNN VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467096/553467096 [==============================] - 19s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138357544 (527.79 MB)\n",
      "Trainable params: 138357544 (527.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "keras.src.engine.functional.Functional"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_model = vgg16.VGG16()\n",
    "vgg16_model.summary()\n",
    "type(vgg16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 100356    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14815044 (56.51 MB)\n",
      "Trainable params: 14815044 (56.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-3]:\n",
    "    model.add(layer)\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.add(Dense(4,activation = 'softmax'))\n",
    "\n",
    "# Sumario do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer= \"adam\",\n",
    "              metrics=['accuracy'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações Finais de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.22 GiB for an array with shape (2870, 224, 224, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pytho\\Documents\\GitHub\\GS-ADS-DOS-CRIA\\AI & CHATBOT\\MRI\\Model\\mod.ipynb Célula 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pytho/Documents/GitHub/GS-ADS-DOS-CRIA/AI%20%26%20CHATBOT/MRI/Model/mod.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\pytho\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\pytho\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:86\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[39mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m     83\u001b[0m   \u001b[39m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[0;32m     84\u001b[0m   \u001b[39m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[0;32m     85\u001b[0m   \u001b[39m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m   value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, ops\u001b[39m.\u001b[39mEagerTensor):\n\u001b[0;32m     88\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtype:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.22 GiB for an array with shape (2870, 224, 224, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1) if Y_pred.ndim > 1 else Y_pred\n",
    "\n",
    "Y_pred_classes = Y_pred_classes.reshape(Y_test.shape\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizando os rótulos para multi-classe\n",
    "Y_test_bin = label_binarize(Y_test, classes=[0, 1, 2, 3])\n",
    "Y_pred_bin = model.predict(X_test)\n",
    "\n",
    "# Calculando ROC para cada classe\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(4):  # Número de classes\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test_bin[:, i], Y_pred_bin[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plote a curva ROC para cada classe\n",
    "for i in range(4):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (area = {roc_auc[i]:.2f})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que 'history' é o retorno do método fit do seu modelo\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Supondo que Y_train e Y_test são suas etiquetas de treino e teste\n",
    "classes, counts = np.unique(Y_train, return_counts=True)\n",
    "plt.bar(classes, counts)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
